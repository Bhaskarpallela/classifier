{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38f0a241-ead5-4853-a967-3e99edb08a50",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Dataset Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe5a14-4d31-4efb-90bb-74dd6306d46b",
   "metadata": {},
   "source": [
    "Generation of email queries by using llama3.2 and ollama locally\n",
    "why llama 3.2 ?\n",
    "LLaMA 3.2 is a powerful open-source language model that excels at:\n",
    "\n",
    "Capturing natural phrasing\n",
    "\n",
    "Generating realistic queries from minimal prompts\n",
    "\n",
    "Avoiding overly formal or robotic language\n",
    "\n",
    "This is crucial for your task, since user queries are often short, casual, and diverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e8a5dd-5a32-4c6f-9b7f-f42c414c77c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Generating queries for:\n",
      "Sender or Recipient: Find emails sent by or received from specific people or addresses.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Unread or Read: Filter emails based on whether they’ve been read or not.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Emails with Attachments: Identify emails that contain attachments of any type or specific formats (e.g., PDF, image).\n",
      "\n",
      "[+] Generating queries for:\n",
      "Important or Starred: Find emails marked as important, flagged, or starred by the user.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Specific Words or Phrases: Search for emails using keywords from the subject or body.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Emails by Date or Time: Locate emails sent or received on specific dates or within time ranges.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Replies or Forwards: Identify emails that are replies to or forwarded versions of other emails.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Thread Length: Find email conversations with many replies (long threads).\n",
      "\n",
      "[+] Generating queries for:\n",
      "Emails with Links: Search for emails that contain hyperlinks or URLs.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Emails with Calendar Invites: Identify emails that include event invitations or calendar information.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Bulk or Promotional Emails: Filter emails classified under promotions, newsletters, or bulk senders.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Emails by Size: Find large or small emails based on total size or attachment size.\n",
      "\n",
      "[+] Generating queries for:\n",
      "CC/BCC Recipients: Search for emails where someone was CC’d or BCC’d.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Archived Emails: Find emails that were archived but not deleted.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Spam or Junk: Locate emails classified as spam or moved to the junk folder.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Action-based Queries: Find emails you might want to delete, archive, forward, or reply to.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Folders, Tabs, or Labels: Search emails by Gmail folders, custom labels, or inbox tabs like Primary/Promotions.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Meeting or Travel Details: Find emails related to scheduled meetings, travel bookings, or itineraries.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Email Status Updates: Search for shipping, order, or service status update emails.\n",
      "\n",
      "[+] Generating queries for:\n",
      "Auto-generated Emails: Filter emails sent from bots, automated systems, or no-reply addresses.\n",
      "\n",
      "[✓] Saving 451 queries to 'email_queries_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "MODEL_NAME = \"llama3.2\"\n",
    "\n",
    "SEED_TOPICS = [\n",
    "    \"Sender or Recipient: Find emails sent by or received from specific people or addresses.\",\n",
    "    \"Unread or Read: Filter emails based on whether they’ve been read or not.\",\n",
    "    \"Emails with Attachments: Identify emails that contain attachments of any type or specific formats (e.g., PDF, image).\",\n",
    "    \"Important or Starred: Find emails marked as important, flagged, or starred by the user.\",\n",
    "    \"Specific Words or Phrases: Search for emails using keywords from the subject or body.\",\n",
    "    \"Emails by Date or Time: Locate emails sent or received on specific dates or within time ranges.\",\n",
    "    \"Replies or Forwards: Identify emails that are replies to or forwarded versions of other emails.\",\n",
    "    \"Thread Length: Find email conversations with many replies (long threads).\",\n",
    "    \"Emails with Links: Search for emails that contain hyperlinks or URLs.\",\n",
    "    \"Emails with Calendar Invites: Identify emails that include event invitations or calendar information.\",\n",
    "    \"Bulk or Promotional Emails: Filter emails classified under promotions, newsletters, or bulk senders.\",\n",
    "    \"Emails by Size: Find large or small emails based on total size or attachment size.\",\n",
    "    \"CC/BCC Recipients: Search for emails where someone was CC’d or BCC’d.\",\n",
    "    \"Archived Emails: Find emails that were archived but not deleted.\",\n",
    "    \"Spam or Junk: Locate emails classified as spam or moved to the junk folder.\",\n",
    "    \"Action-based Queries: Find emails you might want to delete, archive, forward, or reply to.\",\n",
    "    \"Folders, Tabs, or Labels: Search emails by Gmail folders, custom labels, or inbox tabs like Primary/Promotions.\",\n",
    "    \"Meeting or Travel Details: Find emails related to scheduled meetings, travel bookings, or itineraries.\",\n",
    "    \"Email Status Updates: Search for shipping, order, or service status update emails.\",\n",
    "    \"Auto-generated Emails: Filter emails sent from bots, automated systems, or no-reply addresses.\"\n",
    "]\n",
    "\n",
    "def CreatePrompt(seed_topic):\n",
    "    return f\"\"\"You are simulating a user searching their email based on the following category:\n",
    "\n",
    "{seed_topic}\n",
    "\n",
    "Generate 25 realistic and concise natural language queries that a user might type into an email search bar.\n",
    "\n",
    "Guidelines:\n",
    "- Keep queries short, natural, and varied.\n",
    "- Avoid assistant-like phrases (e.g., \"Can you\", \"Please\", \"Hey assistant\").\n",
    "- Make them sound like something a user would quickly type or say when searching.\n",
    "- Cover different ways of asking about the same thing (diversity matters).\n",
    "- Use informal but clear phrasing where appropriate.\n",
    "\n",
    "Return only a **numbered list of 3 example queries**. No extra commentary or explanation.\"\"\"\n",
    "\n",
    "\n",
    "def query_ollama(prompt, temperature=0.3):\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"prompt\": prompt,\n",
    "        \"system\": \"You simulate real user email queries for a virtual assistant..\",\n",
    "        \"temperature\": temperature,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(OLLAMA_URL, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"response\"]\n",
    "\n",
    "def parse_response(text):\n",
    "    queries = []\n",
    "    for line in text.strip().split(\"\\n\"):\n",
    "        if \".\" in line:\n",
    "            parts = line.split(\".\", 1)\n",
    "            query = parts[1].strip()\n",
    "            if query:\n",
    "                queries.append(query)\n",
    "    return queries\n",
    "\n",
    "def generate_queries(seed_topics, output_csv):\n",
    "    all_queries = []\n",
    "    for seed in seed_topics:\n",
    "        print(f\"\\n[+] Generating queries for:\\n{seed}\")\n",
    "        prompt = CreatePrompt(seed)\n",
    "        try:\n",
    "            response = query_ollama(prompt)\n",
    "            queries = parse_response(response)\n",
    "            all_queries.extend([(query, seed.split(\":\")[0].strip()) for query in queries])\n",
    "            time.sleep(1)  # avoid API flooding\n",
    "        except Exception as e:\n",
    "            print(f\"[!] Error for seed '{seed}': {e}\")\n",
    "\n",
    "    # Write to CSV\n",
    "    print(f\"\\n[✓] Saving {len(all_queries)} queries to '{output_csv}'\")\n",
    "    with open(output_csv, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"query\", \"seed\"])\n",
    "        writer.writerows(all_queries)\n",
    "\n",
    "# Run the script\n",
    "generate_queries(SEED_TOPICS, \"email_queries_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e436944b-5a72-4451-a6a8-d5da88e6a2cb",
   "metadata": {},
   "source": [
    "Generation of calender queries by using llama3.2 and ollama locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd826d5d-72b7-48db-8469-b05a947217b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Generating queries for:\n",
      "Meetings with a specific person\n",
      "[+] Generating queries for:\n",
      "Events scheduled for today or tomorrow\n",
      "[+] Generating queries for:\n",
      "Recurring events like weekly standups or classes\n",
      "[+] Generating queries for:\n",
      "Canceled or rescheduled events\n",
      "[+] Generating queries for:\n",
      "Events with Zoom or Google Meet links\n",
      "[+] Generating queries for:\n",
      "Personal events (e.g., birthdays, gym sessions, doctor appointments)\n",
      "[+] Generating queries for:\n",
      "Events at a specific location or city\n",
      "[+] Generating queries for:\n",
      "Free time or availability on a specific day\n",
      "[+] Generating queries for:\n",
      "Overlapping or conflicting events\n",
      "[+] Generating queries for:\n",
      "Events created by me\n",
      "[+] Generating queries for:\n",
      "Reminders or tasks scheduled\n",
      "[+] Generating queries for:\n",
      "All-day events\n",
      "[+] Generating queries for:\n",
      "Events during weekends or holidays\n",
      "[+] Generating queries for:\n",
      "Work-related events or meetings\n",
      "[+] Generating queries for:\n",
      "Events from shared calendars\n",
      "[+] Generating queries for:\n",
      "Events tagged as high priority or urgent\n",
      "[+] Generating queries for:\n",
      "Upcoming events in the next 7 days\n",
      "[+] Generating queries for:\n",
      "Events that were declined or not responded to\n",
      "[+] Generating queries for:\n",
      "One-on-one vs group meetings\n",
      "[+] Generating queries for:\n",
      "Events with certain keywords in title or description\n",
      "[+] Generating queries for:\n",
      "Back-to-back meetings\n",
      "[+] Generating queries for:\n",
      "Past events within a specific date range\n",
      "[+] Generating queries for:\n",
      "Morning or evening events\n",
      "[+] Generating queries for:\n",
      "Events that last more than 1 hour\n",
      "[+] Generating queries for:\n",
      "Recurring events that were skipped or modified\n",
      "[+] Generating queries for:\n",
      "Team meetings involving a specific department\n",
      "[+] Generating queries for:\n",
      "Calendar events that include attachments or documents\n",
      "[+] Generating queries for:\n",
      "Virtual events vs in-person events\n",
      "[+] Generating queries for:\n",
      "Events where I'm marked as 'Maybe'\n",
      "[+] Generating queries for:\n",
      "Events outside my working hours\n",
      "[✓] Saving 493 queries to 'calendar_queries_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Expanded and shuffled Calendar seed topics\n",
    "CALENDAR_SEED_TOPICS = [\n",
    "    \"Meetings with a specific person\",\n",
    "    \"Events scheduled for today or tomorrow\",\n",
    "    \"Recurring events like weekly standups or classes\",\n",
    "    \"Canceled or rescheduled events\",\n",
    "    \"Events with Zoom or Google Meet links\",\n",
    "    \"Personal events (e.g., birthdays, gym sessions, doctor appointments)\",\n",
    "    \"Events at a specific location or city\",\n",
    "    \"Free time or availability on a specific day\",\n",
    "    \"Overlapping or conflicting events\",\n",
    "    \"Events created by me\",\n",
    "    \"Reminders or tasks scheduled\",\n",
    "    \"All-day events\",\n",
    "    \"Events during weekends or holidays\",\n",
    "    \"Work-related events or meetings\",\n",
    "    \"Events from shared calendars\",\n",
    "    \"Events tagged as high priority or urgent\",\n",
    "    \"Upcoming events in the next 7 days\",\n",
    "    \"Events that were declined or not responded to\",\n",
    "    \"One-on-one vs group meetings\",\n",
    "    \"Events with certain keywords in title or description\",\n",
    "    \"Back-to-back meetings\",\n",
    "    \"Past events within a specific date range\",\n",
    "    \"Morning or evening events\",\n",
    "    \"Events that last more than 1 hour\",\n",
    "    \"Recurring events that were skipped or modified\",\n",
    "    \"Team meetings involving a specific department\",\n",
    "    \"Calendar events that include attachments or documents\",\n",
    "    \"Virtual events vs in-person events\",\n",
    "    \"Events where I'm marked as 'Maybe'\",\n",
    "    \"Events outside my working hours\"\n",
    "]\n",
    "\n",
    "\n",
    "def create_calendar_prompt(seed_topic):\n",
    "    return f\"\"\"You are simulating a user searching their calendar or scheduling assistant based on the following category:\n",
    "\n",
    "{seed_topic}\n",
    "\n",
    "Generate 25 realistic and concise natural language queries that a user might type into a calendar app or say to a virtual assistant.\n",
    "\n",
    "Guidelines:\n",
    "- Keep queries short, direct, and natural.\n",
    "- Avoid assistant-style phrasing like \"Can you\", \"Please\", or \"Hey assistant\".\n",
    "- Make them sound like something a person would quickly type when trying to find or manage events.\n",
    "- Include a variety of phrasings for similar intents to ensure diversity.\n",
    "\n",
    "Return only a **numbered list of 3 distinct example queries**. No explanation or extra text.\"\"\"\n",
    "\n",
    "# Send prompt to Ollama and get response\n",
    "def Query_ollama(prompt, temperature=0.3):\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"prompt\": prompt,\n",
    "        \"system\": \"You simulate real user calendar queries for a virtual assistant.\",\n",
    "        \"temperature\": temperature,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(OLLAMA_URL, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"response\"]\n",
    "\n",
    "# Extract queries from model response\n",
    "def parse_Queries(text):\n",
    "    queries = []\n",
    "    for line in text.strip().split(\"\\n\"):\n",
    "        if \".\" in line:\n",
    "            parts = line.split(\".\", 1)\n",
    "            query = parts[1].strip()\n",
    "            if query:\n",
    "                queries.append(query)\n",
    "    return queries\n",
    "\n",
    "# Generate and save queries\n",
    "def generate_Queries(output_csv):\n",
    "    all_queries = []\n",
    "\n",
    "    for seed in CALENDAR_SEED_TOPICS:\n",
    "        print(f\"[+] Generating queries for:\\n{seed}\")\n",
    "        prompt = create_calendar_prompt(seed)\n",
    "        try:\n",
    "            response = Query_ollama(prompt)\n",
    "            queries = parse_Queries(response)\n",
    "            all_queries.extend([(query, seed) for query in queries])\n",
    "            time.sleep(1)  # polite delay\n",
    "        except Exception as e:\n",
    "            print(f\"[!] Error for seed '{seed}': {e}\")\n",
    "\n",
    "    print(f\"[✓] Saving {len(all_queries)} queries to '{output_csv}'\")\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"query\", \"seed_topic\"])\n",
    "        writer.writerows(all_queries)\n",
    "\n",
    "\n",
    "generate_Queries(\"calendar_queries_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d34637-3919-4b13-8b97-a667553645c0",
   "metadata": {},
   "source": [
    "Loading and combinig both csvs which contains their respective queries and inorder to merge for single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15917d3f-79f3-4704-b6cb-c3d7edbd2ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load both CSV files\n",
    "email_df = pd.read_csv(\"email_queries_dataset.csv\")\n",
    "calendar_df = pd.read_csv(\"calendar_queries_dataset.csv\")\n",
    "\n",
    "# Assign labels\n",
    "email_df[\"label\"] = 0\n",
    "calendar_df[\"label\"] = 1\n",
    "\n",
    "# Keep only required columns\n",
    "email_df = email_df[[\"query\", \"label\"]]\n",
    "calendar_df = calendar_df[[\"query\", \"label\"]]\n",
    "\n",
    "# Concatenate both datasets\n",
    "combined_df = pd.concat([email_df, calendar_df], ignore_index=True)\n",
    "\n",
    "# Save to data.csv\n",
    "combined_df.to_csv(\"dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdbc5da7-05ac-433f-92df-53268b1d1b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who sent me that email?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emails from john</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sent to my dad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From my bank</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email from sarah</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     query  label\n",
       "0  Who sent me that email?      0\n",
       "1         Emails from john      0\n",
       "2           Sent to my dad      0\n",
       "3             From my bank      0\n",
       "4         Email from sarah      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c6005ff-418b-4f2c-800c-5d42da7dac6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who sent me that email?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emails from john</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sent to my dad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From my bank</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email from sarah</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recent emails from friends</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who's been emailing me lately</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>All emails from company email</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sarah's emails</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Email address of customer service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               query  label\n",
       "0            Who sent me that email?      0\n",
       "1                   Emails from john      0\n",
       "2                     Sent to my dad      0\n",
       "3                       From my bank      0\n",
       "4                   Email from sarah      0\n",
       "5         Recent emails from friends      0\n",
       "6      Who's been emailing me lately      0\n",
       "7      All emails from company email      0\n",
       "8                     Sarah's emails      0\n",
       "9  Email address of customer service      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#replace the dataset\n",
    "df=pd.read_csv(\"dataset.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c350d16-0855-4e3a-9b32-ff1b89bb92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "gmail_queries = [\n",
    "    \"Find emails with PDF attachments\",\n",
    "    \"Show me unread messages in my inbox\",\n",
    "    \"Search for emails from Sarah about the project proposal\",\n",
    "    \"Find messages with subject line 'quarterly report'\",\n",
    "    \"Show all emails I've received from marketing@company.com\",\n",
    "    \"Find emails with large attachments\",\n",
    "    \"Search for emails I starred last week\",\n",
    "    \"Show me all emails in my Promotions tab\",\n",
    "    \"Find messages with the label 'Urgent'\"\n",
    "]\n",
    "\n",
    "calendar_queries = [\n",
    "    \"When is my next meeting with the design team?\",\n",
    "    \"Show me all events scheduled for next Tuesday\",\n",
    "    \"Find appointments with Dr. Johnson\",\n",
    "    \"When did I schedule the quarterly review?\",\n",
    "    \"Show me all recurring meetings\",\n",
    "    \"Find events where I'm marked as optional\",\n",
    "    \"When is the marketing presentation scheduled?\",\n",
    "    \"Show me all-day events in May\",\n",
    "    \"Find meetings I haven't responded to yet\",\n",
    "    \"When is the team lunch scheduled for?\"\n",
    "]\n",
    "# Save Gmail (label 0)\n",
    "with open('dataset.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for q in gmail_queries:\n",
    "        writer.writerow([q,0])\n",
    "\n",
    "# Save Calendar (label 1)\n",
    "with open('dataset.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for q in calendar_queries:\n",
    "        writer.writerow([q,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029ae4d9-9f64-4ee5-8a31-ab49048657ad",
   "metadata": {},
   "source": [
    "#Model Development\n",
    "#importing requried packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27241534-f0b5-4514-ac79-c5573b18d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dbd174-fda6-414c-89ec-66bf35f34bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade transformers tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eee0f4-0b08-4580-89d3-4e4cfa408ae3",
   "metadata": {},
   "source": [
    "# 3. Train/Val/Test Splitting Dataset\n",
    "splitting dataset into 80 and 20 for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46c18d8d-ce38-4ba6-9117-979fb80365dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df, test_df = train_test_split(combined_df, test_size=0.2, stratify=combined_df['label'], random_state=42)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, stratify=test_df['label'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f883862-5661-4281-b795-3f1be6b9e103",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a8e02-b102-47c7-a960-fa11fd727763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_data(df, tokenizer, max_length=128):\n",
    "    return tokenizer(\n",
    "        df[\"query\"].tolist(),\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"np\"\n",
    "    )\n",
    "\n",
    "# Tokenize all splits\n",
    "train_encodings = tokenize_data(train_df, tokenizer)\n",
    "val_encodings = tokenize_data(val_df, tokenizer)\n",
    "test_encodings = tokenize_data(test_df, tokenizer)\n",
    "\n",
    "# Convert to TensorFlow Datasets manually (use Keras model.fit)\n",
    "def convert_to_dataset(encodings, labels):\n",
    "    inputs = {\n",
    "        \"input_ids\": tf.convert_to_tensor(encodings[\"input_ids\"], dtype=tf.int32),\n",
    "        \"attention_mask\": tf.convert_to_tensor(encodings[\"attention_mask\"], dtype=tf.int32),\n",
    "    }\n",
    "    targets = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "    return tf.data.Dataset.from_tensor_slices((inputs, targets)).batch(16)\n",
    "\n",
    "train_dataset = convert_to_dataset(train_encodings, train_df[\"label\"].values)\n",
    "val_dataset = convert_to_dataset(val_encodings, val_df[\"label\"].values)\n",
    "test_dataset = convert_to_dataset(test_encodings, test_df[\"label\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27329db6-915b-4a74-a5cf-f24754029140",
   "metadata": {},
   "source": [
    "Model Develovement\n",
    "\n",
    "choosing  bert-base-uncased because:\n",
    "\n",
    "It is simple, robust, battle-tested, and works well for English classification tasks .\n",
    "\n",
    "It’s accurate and efficient for moderately sized datasets with informal, lowercase-heavy text (like user queries).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41a9751c-1577-4b1f-b3f4-af80612d86df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "48/48 [==============================] - 611s 12s/step - loss: 0.4650 - accuracy: 0.8000 - val_loss: 0.2233 - val_accuracy: 0.9255\n",
      "Epoch 2/3\n",
      "48/48 [==============================] - 556s 12s/step - loss: 0.1467 - accuracy: 0.9563 - val_loss: 0.1375 - val_accuracy: 0.9574\n",
      "Epoch 3/3\n",
      "48/48 [==============================] - 552s 12s/step - loss: 0.0902 - accuracy: 0.9762 - val_loss: 0.1366 - val_accuracy: 0.9574\n",
      "6/6 [==============================] - 23s 3s/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m model_keras\u001b[38;5;241m.\u001b[39mfit(train_dataset, validation_data\u001b[38;5;241m=\u001b[39mval_dataset, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m logits \u001b[38;5;241m=\u001b[39m model_keras\u001b[38;5;241m.\u001b[39mpredict(test_dataset)\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m     53\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     54\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load model\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Custom training loop with Keras Model wrapper to avoid transformer.fit bug\n",
    "input_ids = tf.keras.Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\n",
    "attention_mask = tf.keras.Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n",
    "outputs = model(input_ids, attention_mask=attention_mask)[0]\n",
    "model_keras = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=outputs)\n",
    "\n",
    "# Compile and train\n",
    "model_keras.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_keras.fit(train_dataset, validation_data=val_dataset, epochs=3)\n",
    "\n",
    "# Evaluate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edbdb86-757a-4efc-9934-3ea4fab61c51",
   "metadata": {},
   "source": [
    "Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "889eb356-a7ce-4022-97c1-c41b1fe06b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 17s 3s/step\n"
     ]
    }
   ],
   "source": [
    "logits = model_keras.predict(test_dataset)\n",
    "pred_labels = tf.argmax(logits, axis=1).numpy()\n",
    "true_labels = test_df[\"label\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8da62-2451-4fbf-9517-3df379980e3e",
   "metadata": {},
   "source": [
    "Model report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28e53d13-f38e-4678-a227-462340519eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93        45\n",
      "           1       0.89      1.00      0.94        50\n",
      "\n",
      "    accuracy                           0.94        95\n",
      "   macro avg       0.95      0.93      0.94        95\n",
      "weighted avg       0.94      0.94      0.94        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9887a6-6502-4f36-8273-ba7cb5e71f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Example\n",
    "user input queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1c02de3-b00d-47dd-8641-83e6f7d27ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Show me unread messages in my inbox => Predicted Class: Gmail\n",
      "Query: When is my next meeting? => Predicted Class: Calendar\n",
      "Query: Search for emails from boss => Predicted Class: Gmail\n",
      "Query: What events are scheduled next Friday? => Predicted Class: Calendar\n"
     ]
    }
   ],
   "source": [
    "def predict_query(query):\n",
    "    inputs = tokenizer(query, return_tensors=\"tf\", truncation=True, padding=True, max_length=128)\n",
    "    logits = model(inputs).logits\n",
    "    prediction = np.argmax(logits, axis=1).item()\n",
    "    return \"Gmail\" if prediction == 0 else \"Calendar\"\n",
    "sample_queries = [\n",
    "    \"Show me unread messages in my inbox\",\n",
    "    \"When is my next meeting?\",\n",
    "    \"Search for emails from boss\",\n",
    "    \"What events are scheduled next Friday?\"\n",
    "]\n",
    "\n",
    "for q in sample_queries:\n",
    "    print(f\"Query: {q} => Predicted Class: {predict_query(q)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c55deeb-2999-47bd-bf90-8b982051c695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "input your query welcome to this seminar meeting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:welcome to this seminar meeting=>Predicted Classs :Calendar\n"
     ]
    }
   ],
   "source": [
    "query=input(\"input your query\")\n",
    "\n",
    "print(f\"query:{query}=>Predicted Classs :{predict_query(query)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de74ff-4320-4b04-8da8-fe3eb674b491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
